{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation \n",
    "Using some Data Augmentation techniques for more data and Better results.\n",
    "    Shearing of images,\n",
    "    Random zoom,\n",
    "    Horizontal flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(r'dataset\\training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_set = test_datagen.flow_from_directory(r'dataset\\test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating a Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer 1:\n",
    "Filters: 32 (number of filters/kernels),\n",
    "Kernel Size: 3x3 (size of the convolutional filter),\n",
    "Activation Function: ReLU (Rectified Linear Unit),\n",
    "Input Shape: (64, 64, 3) (input dimensions for the first layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling Layer 1:\n",
    "Pool Size: 2x2 (size of the pooling window),\n",
    "Strides: 2 (step size of the pooling window)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer 2:\n",
    "Filters: 32,\n",
    "Kernel Size: 3x3,\n",
    "Activation Function: ReLU,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling Layer 2:\n",
    "Pool Size: 2x2 (size of the pooling window),\n",
    "Strides: 2 (step size of the pooling window)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening Layer:\n",
    "Converts the 2D feature maps to a 1D vector for input to the Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer (Dense Layer 1):\n",
    "Units: 128 (number of neurons in the layer),\n",
    "Activation Function: ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer (Dense Layer 2):\n",
    "Units: 1 (binary classification, hence one output neuron),\n",
    "Activation Function: Sigmoid (for binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the CNN:\n",
    "Optimizer: Adam (popular optimization algorithm),\n",
    "Loss Function: Binary Crossentropy (suitable for binary classification),\n",
    "Metrics: Accuracy (evaluation metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN:\n",
    "x: Training data, provided as a generator (training_set)\n",
    "validation_data: Validation data, provided as a generator (test_set)\n",
    "epochs: Number of times the entire training dataset is passed forward and backward through the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 41s 162ms/step - loss: 0.6862 - accuracy: 0.5545 - val_loss: 0.6302 - val_accuracy: 0.6590\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 35s 138ms/step - loss: 0.6201 - accuracy: 0.6605 - val_loss: 0.5904 - val_accuracy: 0.6935\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.5658 - accuracy: 0.7107 - val_loss: 0.5395 - val_accuracy: 0.7335\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 39s 155ms/step - loss: 0.5347 - accuracy: 0.7319 - val_loss: 0.5071 - val_accuracy: 0.7545\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.5154 - accuracy: 0.7452 - val_loss: 0.5946 - val_accuracy: 0.6955\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.5005 - accuracy: 0.7599 - val_loss: 0.5003 - val_accuracy: 0.7645\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 35s 142ms/step - loss: 0.4819 - accuracy: 0.7676 - val_loss: 0.4907 - val_accuracy: 0.7765\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 35s 142ms/step - loss: 0.4761 - accuracy: 0.7681 - val_loss: 0.5040 - val_accuracy: 0.7620\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.4628 - accuracy: 0.7836 - val_loss: 0.4797 - val_accuracy: 0.7785\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.4475 - accuracy: 0.7944 - val_loss: 0.4965 - val_accuracy: 0.7650\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.4378 - accuracy: 0.7920 - val_loss: 0.4662 - val_accuracy: 0.7835\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.4341 - accuracy: 0.7959 - val_loss: 0.4604 - val_accuracy: 0.7895\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.4134 - accuracy: 0.8061 - val_loss: 0.4677 - val_accuracy: 0.7840\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 36s 142ms/step - loss: 0.4084 - accuracy: 0.8084 - val_loss: 0.4526 - val_accuracy: 0.8050\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 35s 141ms/step - loss: 0.4002 - accuracy: 0.8183 - val_loss: 0.4451 - val_accuracy: 0.7945\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.3877 - accuracy: 0.8244 - val_loss: 0.4982 - val_accuracy: 0.7735\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3811 - accuracy: 0.8276 - val_loss: 0.4752 - val_accuracy: 0.7845\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 0.3732 - accuracy: 0.8303 - val_loss: 0.4502 - val_accuracy: 0.8065\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.3607 - accuracy: 0.8365 - val_loss: 0.4724 - val_accuracy: 0.8025\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.3652 - accuracy: 0.8338 - val_loss: 0.4579 - val_accuracy: 0.8000\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 35s 138ms/step - loss: 0.3531 - accuracy: 0.8416 - val_loss: 0.4286 - val_accuracy: 0.8150\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3422 - accuracy: 0.8425 - val_loss: 0.4470 - val_accuracy: 0.8110\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3405 - accuracy: 0.8479 - val_loss: 0.4733 - val_accuracy: 0.8030\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 35s 138ms/step - loss: 0.3264 - accuracy: 0.8571 - val_loss: 0.4493 - val_accuracy: 0.8110\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.3210 - accuracy: 0.8584 - val_loss: 0.4472 - val_accuracy: 0.8165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21fb5dc9970>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying a summary of the CNN architecture:\n",
    "Useful for inspecting the layers, parameters, and output shapes of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 813,217\n",
      "Trainable params: 813,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAGDCAYAAABwcPpaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoY0lEQVR4nO3dd7xdVZnw8d+TBEILLRBaQIqUAQVEQKTjIE0BQYSM+A4iElAQpMgYYVBUZhCUQUVmCEWlKAEFB6RLFektlICKBoeQ0GsKaTzvH2ffcLjcRnZ29j0nv6+f87lnr7P3WuvEy33Os9Y6a0dmIkmS5t6AujsgSVKrM5hKklSSwVSSpJIMppIklWQwlSSpJIOpJEklGUy1QIqIRSPiqoh4PSIuK1HP/hFxw7zsWx0i4tqIOKDufkitymCqfi0iPh8R90fE5IiYVPzR33oeVL0PsAIwNDM/N7eVZObFmbnTPOjPu0TE9hGREXF5p/KNivJb+1jPdyLiot7Oy8xdM/OXc9ldaYFnMFW/FRFHA2cA/0Ej8K0GnAXsOQ+q/wDwl8ycNQ/qqsqLwJYRMbSp7ADgL/OqgWjw74BUkv8RqV+KiKWA7wKHZeblmTklM2dm5lWZ+Y3inMERcUZETCweZ0TE4OK17SNiQkQcExEvFFntgcVrJwEnAvsVGe9BnTO4iFi9yAAHFcdfjIi/R8SbETE+IvZvKr+j6botI+K+Yvj4vojYsum1WyPiexHxp6KeGyJiuR7+GWYAvwNGFNcPBPYFLu70b/XjiHgmIt6IiAciYpuifBfgW03vc2xTP06OiD8BU4E1i7IvF6//d0T8pqn+H0TETRERff3/T1rQGEzVX30cWAS4oodzjge2ADYGNgI2B05oen1FYClgFeAg4GcRsUxmfptGtjsmM5fIzPN66khELA78BNg1M4cAWwIPd3HessDVxblDgdOBqztllp8HDgSGAQsDx/bUNnAB8K/F852Bx4GJnc65j8a/wbLAr4DLImKRzLyu0/vcqOma/weMBIYA/+hU3zHAhsUHhW1o/NsdkO49KnXLYKr+aijwUi/DsPsD383MFzLzReAkGkGiw8zi9ZmZeQ0wGVh3LvvzNvChiFg0Mydl5uNdnPMp4K+ZeWFmzsrMXwNPArs3nfPzzPxLZk4DLqURBLuVmXcCy0bEujSC6gVdnHNRZr5ctPkjYDC9v89fZObjxTUzO9U3FfgCjQ8DFwFfy8wJvdQnLdAMpuqvXgaW6xhm7cbKvDur+kdRNqeOTsF4KrDE++1IZk4B9gMOBSZFxNURsV4f+tPRp1Wajp+bi/5cCBwO7EAXmXoxlP1EMbT8Go1svKfhY4BnenoxM+8F/g4EjaAvqQcGU/VXdwFvAZ/p4ZyJNBYSdViN9w6B9tUUYLGm4xWbX8zM6zPzk8BKNLLNc/rQn44+PTuXfepwIfBV4Joia5yjGIb9Nxpzqctk5tLA6zSCIEB3Q7M9DtlGxGE0MtyJwHFz3XNpAWEwVb+Uma/TWCT0s4j4TEQsFhELRcSuEXFqcdqvgRMiYvliIc+JNIYl58bDwLYRsVqx+GlUxwsRsUJE7FHMnU6nMVw8u4s6rgHWKb7OMygi9gPWB34/l30CIDPHA9vRmCPubAgwi8bK30ERcSKwZNPrzwOrv58VuxGxDvB9GkO9/w84LiI2nrveSwsGg6n6rcw8HTiaxqKiF2kMTR5OY4UrNP7g3w88AjwKPFiUzU1bNwJjiroe4N0BcACNRTkTgVdoBLavdlHHy8Cni3NfppHRfTozX5qbPnWq+47M7Crrvh64lsbXZf5BI5tvHsLt2JDi5Yh4sLd2imH1i4AfZObYzPwrjRXBF3aslJb0XuECPUmSyjEzlSSpJIOpJEklGUwlSSrJYCpJUkkGU0mSSuppd5laPTlpqsuM1fK2OPby3k+SWsBrF3+hshsdLPqRw0v9vZ/20Jm134Sh3wZTSdICog3uAtj670CSpJqZmUqS6tUGt8o1mEqS6tUGw7wGU0lSvdogM239jwOSJNXMzFSSVC+HeSVJKqkNhnkNppKkepmZSpJUUhtkpq3/cUCSpJqZmUqS6uUwryRJJbXBMK/BVJJULzNTSZJKaoPMtPU/DkiSVDMzU0lSvRzmlSSpJIOpJEklDXDOVJKkBZ6ZqSSpXg7zSpJUUht8NcZgKkmql5mpJEkltUFm2vofByRJqpmZqSSpXg7zSpJUUhsM8xpMJUn1MjOVJKmkNshMW//jgCRJNTMzlSTVy2FeSZJKaoNhXoOpJKlebZCZtv47kCSpFxHxdEQ8GhEPR8T9nV47NiIyIpZrKhsVEU9FxJ8jYufe6jczlSTVa/5lpjtk5kvvajpiVeCTwP81la0PjAA2AFYG/hAR62Tm7O4qNjOVJNUrotyjnP8CjgOyqWxP4JLMnJ6Z44GngM17qsRgKkmqVwwo9YiIkRFxf9NjZBetJHBDRDzQ8XpE7AE8m5ljO527CvBM0/GEoqxbDvNKkupVMrvMzNHA6F5O2yozJ0bEMODGiHgSOB7YqaseddVMT5WbmUqS2l5mTix+vgBcAWwHrAGMjYingeHAgxGxIo1MdNWmy4cDE3uq32AqSapXyWHeXquPWDwihnQ8p5GN3peZwzJz9cxcnUYA3SQznwOuBEZExOCIWANYG7i3pzYc5pUk1av6TRtWAK6IRjuDgF9l5nXdnZyZj0fEpcA4YBZwWE8reTsqlSSpNlFxMM3MvwMb9XLO6p2OTwZO7msbBlNJUq2qDqbzg3OmkiSVZGYqSapX6yemBlNJUr3aYZjXYCpJqlU7BFPnTCVJKsnMVJJUq3bITA2mkqRaGUwlSSqr9WOpwVSSVK92yExdgCRJUklmppKkWrVDZmowlSTVymAqSVJJBlNJkspq/VjqAiRJksoyM5Uk1cphXkmSSjKYSpJUUjsEU+dMJUkqycxUklSv1k9MDaaSpHq1wzCvwVSSVCuDqSRJJbVDMHUBkiRJJZmZSpJq1Q6ZqcFUklSv1o+lBlNJUr3MTCVJKqkdgqkLkCRJKsnMVJJUq3bITA2mkqR6tX4sNZhKkurVDpmpc6aSJJVkZtrmZs+ezTGH7M/Q5Ybx76f8BIDfX/5rrr5iDAMHDmTTLbbhi4d+necnTeTwA/ZmlVU/AMA663+Yrx5zQp1dl+Z45IzP8OZbM3n77WTW7GSHf7+W4/fZiN0+Opy3M3nxjbf46v/cxXOvTWO15RbnntN256lJbwBw31MvcfT599b8DtSTdshMDaZt7ve//RWrfmANpk6ZAsAjD93HPXfcyk/Ou5SFFl6Y1159Zc65K648nDPOG1NXV6Ue7f79P/DK5Olzjn9y9ThO/s1YAA7ZeV2O2/vDc4Lm+Ocns823rqmln3r/2iGYOszbxl564Xnuv/sOPvmpveaUXfe/l/HZzx/IQgsvDMDSyyxbV/ekUt6cNnPO88UGDyKzxs6olIgo9egPKs9MI+IDwNqZ+YeIWBQYlJlvVt2u4NwzT+OAQ45k2tSpc8omPvMPxj36EBed9zMWXnhhDvzK0ay93gYAPP/cs3z9yyNYbPHF2f+gw9hgw03q6rr0LplwxTf/mST5+U1/5Ze3PAXACZ/biBHbrMkbU2ey+8k3zjn/A8svwe0n78ab02by/cse5q4/v1hX19UX/SMellJpZhoRBwO/Ac4uioYDv+vh/JERcX9E3H/pRedX2bW2d9+dt7P0MsvywXXXf1f57NmzmfzmG5x21gV88dCjOPU7x5GZLDt0Oc4dcy1nnHsJX/rqMfzoe99i6pTJNfVeeredT7qe7U64hn1OvZmDP7kuW643DIDvXzaWDx1xBZfdOZ6RO60LwHOvTeNDR17Otsdfw7cueoBzDtuaIYsuVGf3tQCoOjM9DNgcuAcgM/8aEcO6OzkzRwOjAZ6cNNVBmxKeeOxh7v3TbTxw9x3MmDGDqVOncPr3j2fo8ivw8W3+mYhgnX/6EAMGDOCN119lqaWXnTP0+8F112ellYfz7DP/mJO1SnV67rVpALz0xnR+f/8zbLLmUO588oU5r//mzqcZc+wO/OdvH2HGrLeZMXkGAGOffoWnn5/MWisO4eHxr3RZt+rXX4Zqy6h6znR6Zs7oOIiIQYBBcj7415FHcP5vruecMddw7ImnsOFHNuPoE07mY1tvzyMPNRZpPPvMP5g5cyZLLrUMr7/2CrNnzwbguYkTmPjs/7HiysPrfAsSAIsNHsgSiwya83yHD6/EExNeY80Vhsw5Z9dNhvPXSa8DMHTIYAYUf5w/sPwSrLniEJ5+wVGW/sw5097dFhHfAhaNiE8CXwWuqrhN9WDH3T7DT3/wHb72xX0YtNBCfH3Ud4kIHh/7IL/6+X8zcOBABgwYyFeOPp4hSy5Vd3clll9yUS4+ajsABg4MfnPn09z0yCQuOHJbPrjSkmQmz7w0haPOvweArdYbxqh9NmL27GT228nR59/Da1Nm9NSEatZP4mEpkRUugYuIAcBBwE40ppivB87NPjTqMK/awRbHXl53F6R54rWLv1BZyPvgsdeW+nv/1A93rT0cV52Z7glckJnnVNyOJKlF9Zeh2jKqnjPdA/hLRFwYEZ8q5kwlSZojotyjP6g0mGbmgcAHgcuAzwN/i4hzq2xTktRaXIDUB5k5MyKupbGKd1EaQ79frrpdSVJr6CfxsJSqN23YJSJ+ATwF7AOcC6xUZZuSJM1vVWemXwQuAQ7JzOm9nCtJWgANGND6qWmlwTQzR1RZvySp9bXDMG8lwTQi7sjMrSPiTd6941EAmZlLVtGuJKn19JdFRGVUEkwzc+vi55DezpUkLdjaIJZWvgDpwr6USZLUyqpegPSuW44UmzZ8tOI2JUktpB2GeSvJTCNiVDFfumFEvFE83gSeB/63ijYlSa1pfmzaEBFPR8SjEfFwRNxflJ0WEU9GxCMRcUVELN10/qiIeCoi/hwRO/dWfyXBNDP/s5gvPS0zlyweQzJzaGaOqqJNSVJrmo/bCe6QmRtn5qbF8Y3AhzJzQ+AvwKhGf2J9YASN0dVdgLMiYmBPFVf91ZhREbEMsDawSFP57VW2K0lSbzLzhqbDu2lsLgSNnfouKfZHGB8RTwGbA3d1V1elwTQivgwcCQwHHga2KDrziSrblSS1jrJzphExEhjZVDQ6M0d3Oi2BGyIigbO7eP1LwJji+So0gmuHCUVZt6pegHQksBlwd2buEBHrASdV3KYkqYWUXX9UBMbOwbGzrTJzYkQMA26MiCc7Rkkj4nhgFnBxR5e6aqanyqu+BdtbmfkWQEQMzswngXUrblOS1ELmxwKkzJxY/HwBuILGsC0RcQDwaWD/zOwImBOAVZsuHw5M7Kn+qoPphGJ11O9ofBL43946JElasFS9ACkiFo+IIR3PgZ2AxyJiF+DfgD0yc2rTJVcCIyJicESsQWPdz709tVH1AqS9iqffiYhbgKWA66psU5KkTlYAriiy2EHArzLzumJh0WAayR40piQPzczHI+JSYByN4d/DMnN2Tw1UvQBp2abDR4ufPY47S5IWLFVv2pCZfwc26qL8gz1cczJwcl/bqHoB0oM0xp1fpTGhuzQwKSJeAA7OzAcqbl+S1M+1wQZIlc+ZXgfslpnLZeZQYFfgUuCrwFkVty1JagHzYwFS1aoOpptm5vUdB8UXZLfNzLtpjFNLkhZw83EHpMpUPcz7SkT8G3BJcbwf8GqxLdPbFbctSdJ8UXVm+nka38/5XfFYtSgbCOxbcduSpBbQDsO8VX815iXgaxGxRGZO7vTyU1W2LUlqDf0kHpZS9c3Bt4yIcTS+q0NEbBQRLjySJM3RDplp1cO8/wXsDLwMkJljgW0rblOSpPmq6gVIZOYznT459LiLhCRpwdJPkstSqg6mz0TElkBGxMLAEcATFbcpSWoh/WWotoyqg+mhwI9p3AduAnADcFjFbUqSWojBtBfFat79q2xDktTa2iCWVhNMI+LEHl7OzPxeFe1KklSHqjLTKV2ULQ4cBAwFDKaSJMBh3m5l5o86nhc3ZD0SOJDGtoI/6u46SdKCpw1iaXVzpsW9TI+mMWf6S2CTzHy1qvYkSa3JzLQbEXEasDcwGvhwF1sJSpIEtEdmWtUOSMcAKwMnABMj4o3i8WZEvFFRm5Ik1aKqOdOqtymUJLWJAW2Qmla+naAkST1pg1hqMJUk1asdFiA5HCtJUklmppKkWg1o/cTUYCpJqlc7DPMaTCVJtWqDWGowlSTVK2j9aOoCJEmSSjIzlSTVygVIkiSV5AIkSZJKaoNYajCVJNWrHfbmdQGSJEklmZlKkmrVBompwVSSVC8XIEmSVFIbxFLnTCVJKsvMVJJUq3ZYzWswlSTVqvVDqcFUklQzFyBJklRSO+zN6wIkSZJKMjOVJNXKYV5Jkkpqg1hqMJUk1cvMVJKkklyAJEmSzEwlSfVymFeSpJJaP5T2IZhG4yPD/sCamfndiFgNWDEz7628d5KkttcOe/P2Zc70LODjwL8Ux28CP6usR5IktZi+DPN+LDM3iYiHADLz1YhYuOJ+SZIWEG2QmPYpmM6MiIFAAkTE8sDblfZKkrTAWFAWIP0EuAIYFhEnA/sAJ1TaK0nSAqMNYmnvwTQzL46IB4B/prHo6jOZ+UTlPZMkLRDmxwKkiHiaxpqf2cCszNw0IpYFxgCrA08D+2bmq8X5o4CDivOPyMzre6q/1wVIxerdqcBVwJXAlKJMkqRWskNmbpyZmxbH3wRuysy1gZuKYyJifWAEsAGwC3BWMd3Zrb4M815NY740gEWANYA/F41IklRKjcO8ewLbF89/CdwK/FtRfklmTgfGR8RTwObAXd1V1Jdh3g83H0fEJsAhc9Pr92P15RerugmpctPH3V13F6R55AuV1TyfFiAlcENEJHB2Zo4GVsjMSQCZOSkihhXnrgI0/8c7oSjr1vveASkzH4yIzd7vdZIkdaXsJvERMRIY2VQ0ugiWzbbKzIlFwLwxIp7sqcouyrKnPvRlB6Sjmw4HAJsAL/Z2nSRJfVE2My0CZ+fg2fmcicXPFyLiChrDts9HxEpFVroS8EJx+gRg1abLhwMTe6q/Lx8IhjQ9BtOYQ92zD9dJklS7iFg8IoZ0PAd2Ah6jsaj2gOK0A4D/LZ5fCYyIiMERsQawNtDjFro9ZqbF6qUlMvMbc/0uJEnqwXy4n+kKwBVFBjwI+FVmXhcR9wGXRsRBwP8BnwPIzMcj4lJgHDALOCwzZ/fUQLfBNCIGZeasYsGRJEmVqDqYZubfgY26KH+Zxh4KXV1zMnByX9voKTO9l8b86MMRcSVwGTClqaHL+9qIJEndWVC2E1wWeBn4BO983zQBg6kkSfQcTIcVK3kf450g2qHHJcKSJPXVfJgzrVxPwXQgsARz8X0bSZL6qg1GeXsMppMy87vzrSeSpAXS/Njovmo9BdPWf3eSpH6v7A5I/UFP76HL5cKSJOndus1MM/OV+dkRSdKCqQ1Ged//RveSJM1L7T5nKklS5doglrbFvK8kSbUyM5Uk1ardN22QJKlyzplKklRSG8RSg6kkqV7tMMzrAiRJkkoyM5Uk1SraYPdag6kkqVbtMMxrMJUk1cpgKklSSdEGy3ldgCRJUklmppKkWjnMK0lSSW0wymswlSTVqx22E3TOVJKkksxMJUm1cs5UkqSS2mCU12AqSarXALcTlCSpnHbITF2AJElSSWamkqRauQBJkqSS2uF7pgZTSVKt2iCWGkwlSfVqh8zUBUiSJJVkZipJqlUbJKYGU0lSvdphiNRgKkmqVbRBatoOHwgkSaqVmakkqVatn5caTCVJNWuHr8YYTCVJtWr9UGowlSTVrA0SUxcgSZJUlpmpJKlW7fDVGIOpJKlW7TBEajCVJNXKzFSSpJJaP5S2R3YtSVKtzEwlSbVymFeSpJLaYYjUYCpJqlU7ZKbt8IFAkqRamZlKkmrV+nmpmakkqWYR5R59ayMGRsRDEfH74njjiLg7Ih6OiPsjYvOmc0dFxFMR8eeI2Lkv9ZuZSpJqNWD+5KZHAk8ASxbHpwInZea1EbFbcbx9RKwPjAA2AFYG/hAR62Tm7J4qNzOVJNWq6sw0IoYDnwLObSpO3gmsSwETi+d7Apdk5vTMHA88BWxOL8xMJUktLSJGAiObikZn5uim4zOA44AhTWVfB66PiB/SSCy3LMpXAe5uOm9CUdYjg6kkqVZRcpi3CJyju3otIj4NvJCZD0TE9k0vfQU4KjN/GxH7AucBO9L1eqjsrQ8GU0lSrSr+mulWwB7FvOgiwJIRcRGwO415VIDLeGcIeAKwatP1w3lnCLhbzplKkmo1gCj16ElmjsrM4Zm5Oo2FRTdn5hdoBMjtitM+Afy1eH4lMCIiBkfEGsDawL29vQczU0lSrWraAOlg4McRMQh4i2LONTMfj4hLgXHALOCw3lbygsFUkrSAyMxbgVuL53cAH+3mvJOBk99P3QZTSVKt2mBrXoOpJKleZVfz9gcGU0lSrQa0fix1Na8kSWWZmUqSauUwryRJJbkASZKkksxMJUkqyQVIkiTJzLTdzZ49m3/Z97MMW2EFzjzr7Dnlv/z5eZz+w1O59Y67WGaZZZk5cyYnnXgCTzwxjtmzZ7H7Hp/hoIMPqbHn0juevPok3pwyndlvv82s2W+z9f6ncvwhu/GlvbfkxVcnA/DtM6/k+jvG8YmPrcf3jtiDhRcaxIyZs/jWGb/jtvv+UvM7UE8c5lW/d/GFF7DmmmsxecrkOWXPTZrEXXfeyUorrTyn7Mbrr2PGzBn89ndXMW3aNPbe41PsstunWGWV4XV0W3qPXUb+mJdfm/Kusp9edAtnXHjTu8pefm0y+3z9bCa9+Drrr7USV511GGvtfML87Krep3ZYgOQwbxt7/rnn+OPtt7LXZ/d5V/lpP/hPjjrmG0TTb3BEMG3qNGbNmsX06W8xaKGFWGLxJeZ3l6XSxv55ApNefB2AcX+bxOCFF2Lhhcwb+rMo+egPKg2mEbFORNwUEY8VxxtGhB8R55NTT/kPjjrmGwwY8M7/zbfefBPDVhjGuuut965zd9xpZxZdbFF23H5rdt5xBw744pdYauml53OPpa5lJleddTh/uvg4vrT3VnPKDx2xLfeOGcX/fHt/lh6y6Huu22vHjRn752eYMXPW/Oyu3qcBEaUe/UHVmek5wChgJkBmPkLjfnJdioiREXF/RNx/3jld3jRdfXTbrbew7LLLsv4GH5pTNm3aNM4Z/T989fAj33P+Y48+wsABA7jxlj9yzfU3ccEvz2fCM8/Mzy5L3frEgf/Flp//AZ85/CwO2W8bttpkLc657I+sv/t3+NiIU3jupTc45ei933XNP625It8/Yk8O//4lNfVaC5Kqxz4Wy8x7492fHLr9iJiZo4HRAG/NIivuW1t7+KEHufXWm7njj7czffp0pkyZzPHfPI5nn53AvnvvCcDzzz/HiH325uJLLuPaq3/Plltvw0ILLcTQoUPZ+COb8PjjjzJ81VV7aUmqXsew7YuvTubKmx9hsw1W508P/m3O6+df/icu/8mhc45XGbY0Y04fyZf//ULGT3hpvvdX70//yC3LqTozfSki1oJGYIyIfYBJFbcp4MijjuHGm2/n2htv5gc/PJ3NPrYFp//4p9z6x7u49sabufbGm1lhhRW55DeXs9zyy7PiSitx7z33kJlMnTqVR8eOZY011qz7bUgstsjCLLHY4DnPd/z4ejz+t4msuNySc87Z8xMbMe5vjT8tSy2xKJf/9FBO/OmV3DX277X0We9TG0yaVp2ZHkYj01wvIp4FxgP7V9ym5sKIf9mfE08Yxd57fhoy2XOvvVln3fV6v1Cq2LChQxhz+sEADBo4kDHX3s+Ndz7Bed/7VzZcdziZyT8mvcLXvv9roDGPutaqy/PNg3fhmwfvAsDuXzlzzldo1P+0w1djIrO60dSIGJiZsyNicWBAZr7Z12sd5lU7WGazw+vugjRPTHvozMoi3j1/e73U3/uPrbVU7dG46mHe8RExGtgC8GOhJOk9Iso9+oOqg+m6wB9oDPeOj4gzI2LrituUJLWQNpgyrTaYZua0zLw0M/cGPgIsCdxWZZuSpBbTBtG08h2QImK7iDgLeBBYBNi36jYlSa0jSv6vP6h0NW9EjAceBi4FvpGZU3q+QpKk1lP1V2M2ysw3Km5DktTC+ssiojIqCaYRcVxmngqcHBHvWfKcmUdU0a4kqfW0QSytLDN9ovh5f0X1S5LaRRtE00qCaWZeVTydmpmXNb8WEZ+rok1JUmvqL4uIyqh6Ne+oPpZJktSyqpoz3RXYDVglIn7S9NKS9HDXGEnSgscFSN2bSGO+dA/ggabyN4GjKmpTktSC2iCWVjZnOhYYGxEXZ6aZqCSpe20QTasa5r00M/cFHur01ZgAMjM3rKJdSZLqUNUw75HFz09XVL8kqU20w2reqoZ5JxVPXwKmZebbEbEOsB5wbRVtSpJaUzssQKr6qzG3A4tExCrATcCBwC8qblOS1ELa4KYxlQfTyMypwN7ATzNzL2D9ituUJLWSNoimlQfTiPg4sD9wdVFW9eb6kiTNV1UHtq/T2PHoisx8PCLWBG6puE1JUgtxAVIvMvM24LaIGBIRS2Tm3wHvGCNJmsMFSL2IiA9HxEPAY8C4iHggIjaosk1JUmtpgynTyudMzwaOzswPZOZqwDHAORW3KUnSfFX1nOnimTlnjjQzb42IxStuU5LUSvpLellC1cH07xHx78CFxfEXgPEVtylJaiHtsACp6mHeLwHLA5cXj+VobNwgSRLQWIBU5tEfVLXR/SLAocAHgUeBYzJzZhVtSZJaWz+Jh6VUlZn+EtiURiDdFTitonYkSapdVXOm62fmhwEi4jzg3orakSS1ujZITasKpnOGdDNzVvSXQW1JUr/TDguQqgqmG0XEG8XzABYtjjtuDr5kRe1KklpMO+RbVd3PdGAV9UqS2k8bxNLKvxojSVLb83ZokqR6tUFqajCVJNXKBUiSJJXUDguQnDOVJLW9iBgYEQ9FxO+byr4WEX+OiMcj4tSm8lER8VTx2s59qd/MVJJUq/mUmB4JPAEsCRAROwB7Ahtm5vSIGFaUrw+MADYAVgb+EBHrZObsnio3M5Uk1aviu4NHxHDgU8C5TcVfAU7JzOkAmflCUb4ncElmTs/M8cBTwOa9tWEwlSTVKsr+L2JkRNzf9BjZqYkzgOOAt5vK1gG2iYh7IuK2iNisKF8FeKbpvAlFWY8c5pUk1arsAqTMHA2M7rru+DTwQmY+EBHbN700CFgG2ALYDLg0Itak61w3e+uDwVSS1M62AvaIiN2ARYAlI+IiGhnn5ZmZwL0R8TaNe25PAFZtun44MLG3RhzmlSTVqsop08wclZnDM3N1GguLbs7MLwC/Az4BEBHrAAsDLwFXAiMiYnBErAGsTR/ufGZmKkmqVU3fMz0fOD8iHgNmAAcUWerjEXEpMA6YBRzW20pegGhc2/+8Nav3MWqpv1tms8Pr7oI0T0x76MzKQt6EV2eU+ns/fJmFa9/2wcxUklQrd0CSJElmppKkerVBYmowlSTVqx2GeQ2mkqRatcMt2JwzlSSpJDNTSVK9Wj8xNZhKkurVBrHUYCpJqpcLkCRJKskFSJIkycxUklSz1k9MDaaSpHq1QSw1mEqS6uUCJEmSSnIBkiRJMjOVJNWrHYZ5zUwlSSrJzFSSVCszU0mSZGYqSapXO6zmNZhKkmrVDsO8BlNJUq3aIJYaTCVJNWuDaOoCJEmSSjIzlSTVygVIkiSV5AIkSZJKaoNYajCVJNWsDaKpC5AkSSrJzFSSVCsXIEmSVFI7LECKzKy7D6pJRIzMzNF190Mqy99l1c050wXbyLo7IM0j/i6rVgZTSZJKMphKklSSwXTB5hyT2oW/y6qVC5AkSSrJzFSSpJIMpi0iIjIiftR0fGxEfKeCdr7V6fjOed2G1CEiZkfEwxHxWERcFhGLvc/rV46I3xTPN46I3Zpe2yMivjmv+yx1xWDaOqYDe0fEchW3865gmplbVtyeFmzTMnPjzPwQMAM49P1cnJkTM3Of4nBjYLem167MzFPmWU+lHhhMW8csGossjur8QkQsHxG/jYj7isdWTeU3RsSDEXF2RPyjIxhHxO8i4oGIeDwiRhZlpwCLFpnCxUXZ5OLnmE6f+n8REZ+NiIERcVrR7iMRcUjl/xJqV38EPhgRyxa/n49ExN0RsSFARGxX/G4+HBEPRcSQiFi9yGoXBr4L7Fe8vl9EfDEizoyIpSLi6YgYUNSzWEQ8ExELRcRaEXFd8d/CHyNivRrfv1qYwbS1/AzYPyKW6lT+Y+C/MnMz4LPAuUX5t4GbM3MT4ApgtaZrvpSZHwU2BY6IiKGZ+U3eyRT279TGJcB+AMUfrn8GrgEOAl4v2t4MODgi1phH71cLiIgYBOwKPAqcBDyUmRvSGCm5oDjtWOCwzNwY2AaY1nF9Zs4ATgTGFL+/Y5peex0YC2xXFO0OXJ+ZM2l8QP1a8d/CscBZlb1JtTX35m0hmflGRFwAHEHTHxJgR2D9eGeDyyUjYgiwNbBXce11EfFq0zVHRMRexfNVgbWBl3to/lrgJxExGNgFuD0zp0XETsCGEdEx1LZUUdf4uX2fWqAsGhEPF8//CJwH3EPjQyGZeXNEDC0+QP4JOL0YNbk8MydE3zd1HUPjw+AtwAjgrIhYAtgSuKypnsHl35IWRAbT1nMG8CDw86ayAcDHM7M5wBLd/KWJiO1pBOCPZ+bUiLgVWKSnRjPzreK8nWn8Ufp1R3U0Ptlf/z7fhwTFSEhzQTe/t5mZp0TE1TTmRe+OiB2Bt/rYzpXAf0bEssBHgZuBxYHXOrcvzQ2HeVtMZr4CXEpjeLXDDcDhHQcRsXHx9A5g36JsJ2CZonwp4NUikK4HbNFU18yIWKib5i8BDqQxxNYRPK8HvtJxTUSsExGLz927kwC4Hdgf5nzwe6kYlVkrMx/NzB8A9wOd5zffBIZ0VWFmTgbupTEl8vvMnJ2ZbwDjI+JzRVsRERtV8YbU/gymrelHQPOq3iOATYsFG+N4Z0XkScBOEfEgjfmoSTT+4FwHDIqIR4DvAXc31TUaeKRjAVInNwDbAn8o5qigMT87DngwIh4DzsYRD5XzHYrfZ+AU4ICi/OvFYqOxNKY5ru103S00pjsejoj9uqh3DPCF4meH/YGDijofB/acd29DCxJ3QGpjxfzm7MycFREfB/7bIS1JmvfMINrbasClxVcCZgAH19wfSWpLZqaSJJXknKkkSSUZTCVJKslgKklSSQZTifJ3L+lU1y86doSKiHMjYv0ezt0+It73zQSKvWarvumBpD4ymEoNPd69JCIGzk2lmfnlzBzXwynb09jSTlILM5hK79Vx95LtI+KWiPgV8Gh3d8gpds45MyLGFdvdDeuoKCJujYhNi+e7ROMOPmMj4qaIWJ1G0D6qyIq3ie7vADQ0Im4o7pZyNo1tHCX1E37PVGrSdPeS64qizYEPZeb4aNyq7vXM3KzYEONPEXED8BFgXeDDwAo0doQ6v1O9ywPnANsWdS2bma9ExP8AkzPzh8V5v6JxB6A7ImI1Gts1/hONOwDdkZnfjYhPASMr/YeQ9L4YTKWGru5esiVwb2Z23AGnuzvkbAv8OjNnAxMj4uYu6t+Cxp12xsOcPZa70t0dgLYF9i6uvbrTHYAk1cxgKjV0dfcSgCnNRXRxh5xo3DS9t91Pog/nQPd3AKKP10uqgXOmUt91d4ec24ERxZzqSsAOXVx7F7BdFDdOL24FBu+900l3dwBqvpPKrrxzByBJ/YDBVOq77u6QcwXwV+BR4L+B2zpfmJkv0pjnvLy4Q0nHnUuuAvbqWIBEz3cA2ra4A9BOwP9V9B4lzQX35pUkqSQzU0mSSjKYSpJUksFUkqSSDKaSJJVkMJUkqSSDqSRJJRlMJUkqyWAqSVJJ/x8WNqDKV9vtkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = cnn.predict(test_set)\n",
    "y_pred = (predictions > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Get true labels\n",
    "y_true = test_set.classes\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'], \n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for any random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(r\"prediction_image.jpg\", target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
